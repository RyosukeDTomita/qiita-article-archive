---
title: Privacy Techの概要をまとめてみる
tags:
  - 秘密計算
  - 差分プライバシー
  - 連合学習
  - PrivacyTech
private: false
updated_at: '2025-01-09T16:26:37+09:00'
id: bcb7f77f861059ff1363
organization_url_name: nri
slide: false
ignorePublish: false
---
## Privacy Techとは

- 個人のプライバシーを保護しつつ，個人データを適切に活用するための技術
- EU一般データ保護規則(GDPR)5項cでは[Data Minimisation(データ最小化の原則)](https://gdpr-info.eu/art-5-gdpr/)が定められている。ざっくりいうと企業が取得する個人情報は最小にすべきであるという原理。
  > adequate, relevant and limited to what is necessary in relation to the purposes for which they are processed (‘data minimisation’);

---

## Privacy Techの技術

- 差分プライバシー
- 秘密計算
- 連合学習

---

## 差分プライバシー
[差分プライバシーとはなにか 寺田雅之](https://www.jstage.jst.go.jp/article/isciesci/63/2/63_58/_pdf/-char/ja)から引用

### 差分プライバシーの登場背景

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3718390/96a65811-d6f6-72f4-62df-e8a4a4fd86bb.png)
このケースではプライバシーが開示されてしまう例を示している。男性の合格者は0のため，試験結果を好評することでA君が落第したことが世間に公開されてしまう。

そこで，上記の結果をそのまま公開するのではなく，プライバシーの保護技術にで書き換えて構築したものを元に安全指標を定義している。

### モザイク効果問題

> 複数の（それぞれ安全そうに見える）問合せ結果を「重ね合わせ」ることによりプライバシー開示が発生する問題はモザイク効果 (mosaic effect)[17] 問題とよばれる 1 ．モザイク効果によるプライバシー開示のリスクは，扱う属性が多い大規模なデータに対してより大きく現れ，たとえば公的機関によるオープンデータの充実に向けた課題として議論されている。

### 差分プライバシーとは

差分プライバシーとは: プライバシー保護の安全性を網羅的に定義するための指標で前述のモザイク効果問題を考慮して以下の安全性指標を構築している。

> • 任意の背景知識をもつ攻撃者による，
> • どのようなアルゴリズムによる攻撃に対しても，
> プライバシーの開示を一定以下に抑えることを保証できる安全性指標と，これによるプライバシー保護方式 Q′やその出力 Q′(D) の評価が重要となる．このような性質をもつプライバシーに関する安全性指標，すなわち特定の攻撃に対してのみ “ad hoc” にしか安全性を保証しない指標ではなく，任意の攻撃に対して“ad omnia” に安全性を保証できることを目的として構築された安全性指標が差分プライバシーである．

定義しとしては以下になる

>【定義 1】 任意の隣接したデータベース D1 および1差分による開示 (disclosure by differencing)[14] の一種ともみなせる．
> D2 (D1,D2 ∈ D) に対し，ランダム化関数 (randomized function) Q′ : D → R が下式を満たすとき，Q′ は ϵ-差分プライバシー (ϵ-DP) を満たす．ただし，ここで S はQ′ の出力空間 R の任意の部分空間である (S ⊆ R)

```math
\Pr[Q'(D_1) \in S] \leq e^x \cdot \Pr[Q'(D_2) \in S]
```

> さて，定義 1 は何を意味するだろうか．一見だけではプライバシー保護と何の関係があるかすらわかりにくい．そこで，以下に（なるべく）直感的な説明を試みる．基本的な考え方としては，定義 1 は以下を意味する．
> • あるデータベース D1 と，D1 からある人（A さんとする）の情報を抜いた（もしくは他人の情報と入れ替えた）データベース D2 があるとする．
> • D2 は A さんの情報を含まないので，そこから得られた問合せ結果 Q′(D2) は，A さんのプライバシーを開示しようがない（安全である）．
> • （A さんの情報を含む）データベース D1 から得られた問合せ結果 Q′(D1) が，Q′(D2) とほとんど見分けがつかないなら，Q′(D1) も A さんにとって安全といえる．どのくらい見分けがつかなければ安全とするかは ϵ の値により定める．
> • 任意の D1 と D2 の組合せに対して上記が成立するなら，A さん以外も含めたすべての人にとってQ'は安全といえる.
> • このとき，Q′ は ϵ-差分プライバシーを満たす．

### 差分プライバシーを使うと何が嬉しいのか

個人データの推定を困難にすることでプライバシーに配慮しつつ，全体として統計的な傾向を得ることが可能になる。

---

## 秘密計算

[NRIの用語解説](https://www.nri.com/jp/knowledge/glossary/lst/ha/secure_computation)，[秘密計算の主な手法をまとめる](https://acompany.tech/privacytechlab/technology-secure-computing)にわかりやすそうなのがあったので上げておく。

ざっくりいうと，データを暗号化したまま処理できるため，データを安全に秘匿したまま活用出来る技術のため安全かつ，複数組織のデータを秘匿したまま結合して分析することも可能になる。

### 秘密計算の種類

- 完全準同型暗号を用いる方法: 暗号文での乗算が元データの乗算と対応付けられる計算可能な暗号のこと
- TEE(Trusted Execution Environment)を用いる方法: デイバイスの目盛り上に暗号学的に保護された領域(Enclave)を構築し，その中で機密情報の計算を行う
- MPC(Multi-Party Computation)を用いる方法: 複数のサーバが協力して計算を行う技術

### 様々な秘密計算の実現方法

[秘密計算の発展](https://www.jstage.jst.go.jp/article/essfr/12/1/12_12/_pdf/-char/ja)より

#### 秘密分散を扱う方法

- 秘密分散とは: 秘密情報をシェア(いくつかの断片)に変換する
- あらかじめ決めたシェアの組み合わせからは秘密情報が復元できるが，それ以外のシェアの組からは秘密情報がもれないようにする
- (k，n)しきい法: k個以上のシェアからは秘密情報の復元が可能になる。k-1個のシェアが攻撃者に取得されても問題ない。
- 具体的構成はシャミアの秘密分散法を参照。

https://qiita.com/sigma_devsecops/items/31fd8365c6a2486a3b13

#### Garbled circuitを使う方法

garble circuitについて調べる。TODO

---

## 連合学習

[NRI用語解説](https://www.nri.com/jp/knowledge/glossary/lst/ra/federated_learning)

> 分散しているデータを1か所に集めずに、AIモデルを分散している環境に配布しながらセキュアにモデリングする方法のことです。組織を超えたモデルを構築する際に、組織間のデータを直接やり取りすることを避け、モデルを組織間でやり取りすることで、データ利用の高度化とプライバシー保護を同時に解決する方法です。 

従来の機械学習では，データをサーバに集めて学習を行う必要がある。しかし，連合学習では，各組織が学習させたAIモデルを中央サーバに集めて集約することで中央サーバのモデルを更新できるため，直接のデータのやりとりが必要ないのが特徴。
